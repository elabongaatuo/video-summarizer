{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIAiLQ5o826eangFpoT2Z6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elabongaatuo/video-summarizer/blob/main/video_summarizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5QscYsLzCVvc"
      },
      "outputs": [],
      "source": [
        " # import library that aids in transcription (speech to text)\n",
        "!pip install -q moviepy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q SpeechRecognition"
      ],
      "metadata": {
        "id": "1L6orT3mHY3N",
        "outputId": "ed9ee229-2aca-48a9-b87e-f6aaf3bd08b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import library to aid youtube video download\n",
        "!pip install -q yt_dlp"
      ],
      "metadata": {
        "id": "s4CACzZGCoaJ",
        "outputId": "7a696dad-a9ca-4e69-b344-4c8847f4459b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import model\n",
        "!pip install --upgrade --q huggingface_hub"
      ],
      "metadata": {
        "id": "wNqA4vDyEl3x"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "HUGGINGFACEHUB_API_TOKEN = userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "id": "EbytDT02DCfr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assign hugging face token to a variable\n",
        "import os\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN"
      ],
      "metadata": {
        "id": "ni-VksMXDTeU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download youtube video as mp4 file\n",
        "import yt_dlp\n",
        "\n",
        "def download_mp4_from_youtube(url):\n",
        "    # Set the options for the download\n",
        "    filename = 'onflirting.mp4'\n",
        "    ydl_opts = {\n",
        "        'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]',\n",
        "        'outtmpl': filename,\n",
        "        'quiet': True,\n",
        "    }\n",
        "\n",
        "    # Download the video file\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        result = ydl.extract_info(url, download=True)\n",
        "\n",
        "url = \"https://www.youtube.com/watch?v=rZTqF5oYUqo\"\n",
        "download_mp4_from_youtube(url)\n"
      ],
      "metadata": {
        "id": "pS8h4B-QE9RJ",
        "outputId": "ec6d0c1b-bf8c-4683-a993-6ab9021a216a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing Transformer\n",
        "\n",
        "!pip install -q transformers"
      ],
      "metadata": {
        "id": "fvw8sUvMFyOP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary library\n",
        "\n",
        "# For managing audio file\n",
        "import librosa\n",
        "\n",
        "#Importing Pytorch\n",
        "import torch\n",
        "\n",
        "#Importing Wav2Vec\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer"
      ],
      "metadata": {
        "id": "MAKMXP6tZynI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q ffmpeg-python"
      ],
      "metadata": {
        "id": "jZb2ZV6eaKF6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import speech_recognition as sr\n",
        "import ffmpeg"
      ],
      "metadata": {
        "id": "oPi8Ck3ZaO70"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "command2mp3 = \"ffmpeg -i onflirting.mp4 onflirting.mp3\""
      ],
      "metadata": {
        "id": "xF2BCIW7aXAv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "command2wav = \"ffmpeg -i onflirting.mp3 onflirting.wav\""
      ],
      "metadata": {
        "id": "Yey7SaGRab0c"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.system(command2mp3)\n",
        "os.system(command2wav)"
      ],
      "metadata": {
        "id": "Veop5nZfagmq",
        "outputId": "f3372070-a8bd-4d81-ec4e-1abb27478dbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = sr.Recognizer()\n",
        "with sr.AudioFile('onflirting.wav') as source:\n",
        "     audio = r.record(source, duration=120)\n",
        "result = r.recognize_google(audio)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "ZTVr9x9Xal5l",
        "outputId": "fd073765-7c78-44d8-e8ce-58fcc8e088bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "flirting has a bad name too often it seems a supreme form of duplicity a sly attempt to excite another person and derive gratification from their interest without any corresponding wish to go to bed with them it looks like a manipulative promise of sexual affection that at the last moment leaves its targets confused and humiliated in our sadness back home alone after the nightclub or the party we may rail against the flirt for only flirting when it appeared there would be so much more but this kind of pattern represents only one on edifying and regrettable possibility around flirting at its best flirting can be a vital social process that generously lends us reassurance and freely redistributes confidence and self-esteem the task is not to stop flirting but you learn how better to practice it's most honourable versions good flirting is in essence an attempt driven by kindness and imaginative excitement to inspire another person to believe more firmly in their own likeability psychological as much as physical it is a gift offered not in order to manipulate but out of a pleasure and perceiving what's most attractive in another along the way the good flood must carefully convince us of three apparently contradictory things that they would love to sleep with us that they won't sleep with us and that the reason why has nothing to do with any deficiency on our part good flirting exploits with no evil intent and important truth about sex what is often most enjoyable About Sex is not the physical process itself so much as the idea of acceptance that underpins the act the notion that another person likes us enough to accept us in almost raw and vulnerable state and is in our name willing to lose control and surrender aspects of everyday dignity it is this concept\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open ('text.txt', 'w') as file:\n",
        "    file.write(result)"
      ],
      "metadata": {
        "id": "GXpvO6-KbDau"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain"
      ],
      "metadata": {
        "id": "RfYjm06dclWq"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import HuggingFaceHub, LLMChain\n",
        "from langchain.chains.mapreduce import MapReduceChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN\n",
        "\n",
        "llm = HuggingFaceHub(\n",
        "    repo_id=\"HuggingFaceH4/zephyr-7b-beta\",\n",
        "    task=\"text-generation\",\n",
        "    model_kwargs={\n",
        "    \"max_new_tokens\": 256,    # Adjust based on desired output length\n",
        "    \"top_k\": 30,              # Balance between diversity and focus\n",
        "    \"temperature\": 0.8,       # Moderate randomness for diverse outputs\n",
        "    \"repetition_penalty\": 1.2, # Increase to penalize repetition more\n",
        "    },\n",
        ")\n",
        ""
      ],
      "metadata": {
        "id": "z9EgwTHsbw-a"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000, chunk_overlap=0, separators=[\" \", \",\", \"\\n\"]\n",
        ")"
      ],
      "metadata": {
        "id": "zVX3qNPFdCkb"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.docstore.document import Document\n",
        "\n",
        "with open('text.txt') as f:\n",
        "    text = f.read()\n",
        "\n",
        "texts = text_splitter.split_text(text)\n",
        "docs = [Document(page_content=t) for t in texts[:4]]"
      ],
      "metadata": {
        "id": "bgzOFMwcdK2d"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.summarize import load_summarize_chain\n",
        "import textwrap\n",
        "\n",
        "chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
        "\n",
        "output_summary = chain.invoke(docs)\n",
        "wrapped_text = textwrap.fill(output_summary, width=100)\n",
        "print(wrapped_text)"
      ],
      "metadata": {
        "id": "DgwQpTssdjQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print( chain.llm_chain.prompt.template )"
      ],
      "metadata": {
        "id": "TIILFFUqd-QD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}